{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with the basic files provided, test.csv, train.csv and structures.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training sample:  (4658147, 6)\n",
      "Shape of testing sample:  (2505542, 5)\n",
      "Shape of structures sample:  (2358657, 6)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('champs-scalar-coupling/train.csv')\n",
    "test_df = pd.read_csv('champs-scalar-coupling/test.csv')\n",
    "structures_df = pd.read_csv('champs-scalar-coupling/structures.csv')\n",
    "\n",
    "print(\"Shape of training sample: \",train_df.shape)\n",
    "print(\"Shape of testing sample: \",test_df.shape)\n",
    "print(\"Shape of structures sample: \",structures_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use an exploratory analysis from here: https://www.kaggle.com/artgor/molecular-properties-eda-and-models\n",
    "\n",
    "The basic features provided in the training set are only the atom indices and the coupling type between them, however by enriching the Dataframe with info from the structures file, we can add a couple of more features:\n",
    "\n",
    "- The atom types\n",
    "- The distance between the atoms, in 3 dimensions and combined\n",
    "- The distance relative to the average type distance\n",
    "\n",
    "Let's give this a go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>molecule_name</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>type</th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.8076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.2570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.2548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.2543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.8074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     molecule_name  atom_index_0  atom_index_1  type  \\\n",
       "0   0  dsgdb9nsd_000001             1             0  1JHC   \n",
       "1   1  dsgdb9nsd_000001             1             2  2JHH   \n",
       "2   2  dsgdb9nsd_000001             1             3  2JHH   \n",
       "3   3  dsgdb9nsd_000001             1             4  2JHH   \n",
       "4   4  dsgdb9nsd_000001             2             0  1JHC   \n",
       "\n",
       "   scalar_coupling_constant  \n",
       "0                   84.8076  \n",
       "1                  -11.2570  \n",
       "2                  -11.2548  \n",
       "3                  -11.2543  \n",
       "4                   84.8074  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule_name</th>\n",
       "      <th>atom_index</th>\n",
       "      <th>atom</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.001976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>2</td>\n",
       "      <td>H</td>\n",
       "      <td>1.011731</td>\n",
       "      <td>1.463751</td>\n",
       "      <td>0.000277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>3</td>\n",
       "      <td>H</td>\n",
       "      <td>-0.540815</td>\n",
       "      <td>1.447527</td>\n",
       "      <td>-0.876644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>4</td>\n",
       "      <td>H</td>\n",
       "      <td>-0.523814</td>\n",
       "      <td>1.437933</td>\n",
       "      <td>0.906397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      molecule_name  atom_index atom         x         y         z\n",
       "0  dsgdb9nsd_000001           0    C -0.012698  1.085804  0.008001\n",
       "1  dsgdb9nsd_000001           1    H  0.002150 -0.006031  0.001976\n",
       "2  dsgdb9nsd_000001           2    H  1.011731  1.463751  0.000277\n",
       "3  dsgdb9nsd_000001           3    H -0.540815  1.447527 -0.876644\n",
       "4  dsgdb9nsd_000001           4    H -0.523814  1.437933  0.906397"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structures_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>molecule_name</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>type</th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "      <th>atom_0</th>\n",
       "      <th>x_0</th>\n",
       "      <th>y_0</th>\n",
       "      <th>z_0</th>\n",
       "      <th>atom_1</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>z_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.8076</td>\n",
       "      <td>H</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.2570</td>\n",
       "      <td>H</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>H</td>\n",
       "      <td>1.011731</td>\n",
       "      <td>1.463751</td>\n",
       "      <td>0.000277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.2548</td>\n",
       "      <td>H</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>H</td>\n",
       "      <td>-0.540815</td>\n",
       "      <td>1.447527</td>\n",
       "      <td>-0.876644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.2543</td>\n",
       "      <td>H</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>H</td>\n",
       "      <td>-0.523814</td>\n",
       "      <td>1.437933</td>\n",
       "      <td>0.906397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.8074</td>\n",
       "      <td>H</td>\n",
       "      <td>1.011731</td>\n",
       "      <td>1.463751</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     molecule_name  atom_index_0  atom_index_1  type  \\\n",
       "0   0  dsgdb9nsd_000001             1             0  1JHC   \n",
       "1   1  dsgdb9nsd_000001             1             2  2JHH   \n",
       "2   2  dsgdb9nsd_000001             1             3  2JHH   \n",
       "3   3  dsgdb9nsd_000001             1             4  2JHH   \n",
       "4   4  dsgdb9nsd_000001             2             0  1JHC   \n",
       "\n",
       "   scalar_coupling_constant atom_0       x_0       y_0       z_0 atom_1  \\\n",
       "0                   84.8076      H  0.002150 -0.006031  0.001976      C   \n",
       "1                  -11.2570      H  0.002150 -0.006031  0.001976      H   \n",
       "2                  -11.2548      H  0.002150 -0.006031  0.001976      H   \n",
       "3                  -11.2543      H  0.002150 -0.006031  0.001976      H   \n",
       "4                   84.8074      H  1.011731  1.463751  0.000277      C   \n",
       "\n",
       "        x_1       y_1       z_1  \n",
       "0 -0.012698  1.085804  0.008001  \n",
       "1  1.011731  1.463751  0.000277  \n",
       "2 -0.540815  1.447527 -0.876644  \n",
       "3 -0.523814  1.437933  0.906397  \n",
       "4 -0.012698  1.085804  0.008001  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Joining structure data onto train/test set\n",
    "tmp_with_atom0_info = (train_df\n",
    "                           .merge( structures_df, left_on = ['molecule_name','atom_index_0'], right_on = ['molecule_name','atom_index'], how = 'left' )\n",
    "                           .drop('atom_index', axis=1)\n",
    "                       )\n",
    "tmp_with_atom0_info = tmp_with_atom0_info.rename(columns={ 'atom' : 'atom_0', 'x' : 'x_0', 'y' : 'y_0', 'z' : 'z_0'})\n",
    "\n",
    "tmp_with_atom1_info = (tmp_with_atom0_info\n",
    "                           .merge( structures_df, left_on = ['molecule_name','atom_index_1'], right_on = ['molecule_name','atom_index'], how = 'left' )\n",
    "                           .drop('atom_index', axis=1)\n",
    "                       )\n",
    "tmp_with_atom1_info = tmp_with_atom1_info.rename(columns={ 'atom' : 'atom_1', 'x' : 'x_1', 'y' : 'y_1', 'z' : 'z_1'})\n",
    "\n",
    "train_df = tmp_with_atom1_info\n",
    "\n",
    "tmp_with_atom0_info = (test_df\n",
    "                           .merge( structures_df, left_on = ['molecule_name','atom_index_0'], right_on = ['molecule_name','atom_index'], how = 'left' )\n",
    "                           .drop('atom_index', axis=1)\n",
    "                       )\n",
    "tmp_with_atom0_info = tmp_with_atom0_info.rename(columns={ 'atom' : 'atom_0', 'x' : 'x_0', 'y' : 'y_0', 'z' : 'z_0'})\n",
    "\n",
    "tmp_with_atom1_info = (tmp_with_atom0_info\n",
    "                           .merge( structures_df, left_on = ['molecule_name','atom_index_1'], right_on = ['molecule_name','atom_index'], how = 'left' )\n",
    "                           .drop('atom_index', axis=1)\n",
    "                       )\n",
    "tmp_with_atom1_info = tmp_with_atom1_info.rename(columns={ 'atom' : 'atom_1', 'x' : 'x_1', 'y' : 'y_1', 'z' : 'z_1'})\n",
    "\n",
    "test_df = tmp_with_atom1_info\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del structures_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing distances\n",
    "\n",
    "train_p_0 = train_df[['x_0', 'y_0', 'z_0']].values\n",
    "train_p_1 = train_df[['x_1', 'y_1', 'z_1']].values\n",
    "test_p_0 = test_df[['x_0', 'y_0', 'z_0']].values\n",
    "test_p_1 = test_df[['x_1', 'y_1', 'z_1']].values\n",
    "\n",
    "train_df['dist'] = np.linalg.norm(train_p_0 - train_p_1, axis=1)\n",
    "test_df['dist'] = np.linalg.norm(test_p_0 - test_p_1, axis=1)\n",
    "train_df['dist_x'] = (train_df['x_0'] - train_df['x_1']) ** 2\n",
    "test_df['dist_x'] = (test_df['x_0'] - test_df['x_1']) ** 2\n",
    "train_df['dist_y'] = (train_df['y_0'] - train_df['y_1']) ** 2\n",
    "test_df['dist_y'] = (test_df['y_0'] - test_df['y_1']) ** 2\n",
    "train_df['dist_z'] = (train_df['z_0'] - train_df['z_1']) ** 2\n",
    "test_df['dist_z'] = (test_df['z_0'] - test_df['z_1']) ** 2\n",
    "\n",
    "train_df['type_0'] = train_df['type'].apply(lambda x: x[0])\n",
    "test_df['type_0'] = test_df['type'].apply(lambda x: x[0])\n",
    "\n",
    "train_df['type_1'] = train_df['type'].apply(lambda x: x[1:])\n",
    "test_df['type_1'] = test_df['type'].apply(lambda x: x[1:])\n",
    "\n",
    "# Some more distances related to average molecule and type distances\n",
    "# Freely adapted after https://www.kaggle.com/artgor/brute-force-feature-engineering\n",
    "def create_features(df):\n",
    "    df['molecule_couples'] = df.groupby('molecule_name')['id'].transform('count')\n",
    "    df['molecule_dist_mean'] = df.groupby('molecule_name')['dist'].transform('mean')\n",
    "    df['molecule_dist_min'] = df.groupby('molecule_name')['dist'].transform('min')\n",
    "    df['molecule_dist_max'] = df.groupby('molecule_name')['dist'].transform('max')\n",
    "    df['atom_0_couples_count'] = df.groupby(['molecule_name', 'atom_index_0'])['id'].transform('count')\n",
    "    df['atom_1_couples_count'] = df.groupby(['molecule_name', 'atom_index_1'])['id'].transform('count')\n",
    "    \n",
    "    df[f'molecule_atom_index_0_x_1_std'] = df.groupby(['molecule_name', 'atom_index_0'])['x_1'].transform('std')\n",
    "    df[f'molecule_atom_index_0_y_1_mean'] = df.groupby(['molecule_name', 'atom_index_0'])['y_1'].transform('mean')\n",
    "    df[f'molecule_atom_index_0_y_1_mean_diff'] = df[f'molecule_atom_index_0_y_1_mean'] - df['y_1']\n",
    "    df[f'molecule_atom_index_0_y_1_mean_div'] = df[f'molecule_atom_index_0_y_1_mean'] / df['y_1']\n",
    "    df[f'molecule_atom_index_0_y_1_max'] = df.groupby(['molecule_name', 'atom_index_0'])['y_1'].transform('max')\n",
    "    df[f'molecule_atom_index_0_y_1_max_diff'] = df[f'molecule_atom_index_0_y_1_max'] - df['y_1']\n",
    "    df[f'molecule_atom_index_0_y_1_std'] = df.groupby(['molecule_name', 'atom_index_0'])['y_1'].transform('std')\n",
    "    df[f'molecule_atom_index_0_z_1_std'] = df.groupby(['molecule_name', 'atom_index_0'])['z_1'].transform('std')\n",
    "    df[f'molecule_atom_index_0_dist_mean'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('mean')\n",
    "    df[f'molecule_atom_index_0_dist_mean_diff'] = df[f'molecule_atom_index_0_dist_mean'] - df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_mean_div'] = df[f'molecule_atom_index_0_dist_mean'] / df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_max'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('max')\n",
    "    df[f'molecule_atom_index_0_dist_max_diff'] = df[f'molecule_atom_index_0_dist_max'] - df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_max_div'] = df[f'molecule_atom_index_0_dist_max'] / df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_min'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('min')\n",
    "    df[f'molecule_atom_index_0_dist_min_diff'] = df[f'molecule_atom_index_0_dist_min'] - df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_min_div'] = df[f'molecule_atom_index_0_dist_min'] / df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_std'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('std')\n",
    "    df[f'molecule_atom_index_0_dist_std_diff'] = df[f'molecule_atom_index_0_dist_std'] - df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_std_div'] = df[f'molecule_atom_index_0_dist_std'] / df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_mean'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('mean')\n",
    "    df[f'molecule_atom_index_1_dist_mean_diff'] = df[f'molecule_atom_index_1_dist_mean'] - df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_mean_div'] = df[f'molecule_atom_index_1_dist_mean'] / df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_max'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('max')\n",
    "    df[f'molecule_atom_index_1_dist_max_diff'] = df[f'molecule_atom_index_1_dist_max'] - df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_max_div'] = df[f'molecule_atom_index_1_dist_max'] / df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_min'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('min')\n",
    "    df[f'molecule_atom_index_1_dist_min_diff'] = df[f'molecule_atom_index_1_dist_min'] - df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_min_div'] = df[f'molecule_atom_index_1_dist_min'] / df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_std'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('std')\n",
    "    df[f'molecule_atom_index_1_dist_std_diff'] = df[f'molecule_atom_index_1_dist_std'] - df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_std_div'] = df[f'molecule_atom_index_1_dist_std'] / df['dist']\n",
    "    df[f'molecule_atom_1_dist_mean'] = df.groupby(['molecule_name', 'atom_1'])['dist'].transform('mean')\n",
    "    df[f'molecule_atom_1_dist_min'] = df.groupby(['molecule_name', 'atom_1'])['dist'].transform('min')\n",
    "    df[f'molecule_atom_1_dist_min_diff'] = df[f'molecule_atom_1_dist_min'] - df['dist']\n",
    "    df[f'molecule_atom_1_dist_min_div'] = df[f'molecule_atom_1_dist_min'] / df['dist']\n",
    "    df[f'molecule_atom_1_dist_std'] = df.groupby(['molecule_name', 'atom_1'])['dist'].transform('std')\n",
    "    df[f'molecule_atom_1_dist_std_diff'] = df[f'molecule_atom_1_dist_std'] - df['dist']\n",
    "    df[f'molecule_type_0_dist_std'] = df.groupby(['molecule_name', 'type_0'])['dist'].transform('std')\n",
    "    df[f'molecule_type_0_dist_std_diff'] = df[f'molecule_type_0_dist_std'] - df['dist']\n",
    "    df[f'molecule_type_1_dist_std'] = df.groupby(['molecule_name', 'type_1'])['dist'].transform('std')\n",
    "    df[f'molecule_type_1_dist_std_diff'] = df[f'molecule_type_1_dist_std'] - df['dist']\n",
    "    df[f'molecule_type_dist_mean'] = df.groupby(['molecule_name', 'type'])['dist'].transform('mean')\n",
    "    df[f'molecule_type_dist_mean_diff'] = df[f'molecule_type_dist_mean'] - df['dist']\n",
    "    df[f'molecule_type_dist_mean_div'] = df[f'molecule_type_dist_mean'] / df['dist']\n",
    "    df[f'molecule_type_dist_max'] = df.groupby(['molecule_name', 'type'])['dist'].transform('max')\n",
    "    df[f'molecule_type_dist_min'] = df.groupby(['molecule_name', 'type'])['dist'].transform('min')\n",
    "    df[f'molecule_type_dist_std'] = df.groupby(['molecule_name', 'type'])['dist'].transform('std')\n",
    "    df[f'molecule_type_dist_std_diff'] = df[f'molecule_type_dist_std'] - df['dist']\n",
    "\n",
    "    return df\n",
    "\n",
    "train_df = create_features(train_df)\n",
    "test_df = create_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2505542, 74)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting categorical columns\n",
    "# All categories are present in both train/test so we don't have to worry about data leakage.\n",
    "\n",
    "# Also doing train/test split\n",
    "\n",
    "X = train_df.drop(['id', 'molecule_name', 'scalar_coupling_constant'], axis=1)\n",
    "X_test = test_df.drop(['id', 'molecule_name'], axis=1)\n",
    "y = train_df['scalar_coupling_constant']\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=42)\n",
    "\n",
    "del train_df, test_df\n",
    "del X, y\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), ['atom_0', 'atom_1', 'type', 'type_0', 'type_1'])\n",
    "    ], remainder = 'passthrough' )\n",
    "\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_valid_processed = preprocessor.transform(X_valid)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "del X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating XGB model\n",
    "\n",
    "# verbose=10000 \n",
    "# early_stopping_rounds=200\n",
    "# n_estimators=1\n",
    "\n",
    "# model = XGBRegressor(verbose=verbose, early_stopping_rounds=early_stopping_rounds, n_estimators=n_estimators, nthread=-1)\n",
    "\n",
    "# model.fit(X_train_processed,y_train, \n",
    "#               eval_set=[(X_valid_processed, y_valid)], \n",
    "#               eval_metric='mae',\n",
    "#               verbose=True)\n",
    "# y_pred_valid = model.predict(X_valid_processed)\n",
    "# y_pred = model.predict(X_test_processed)\n",
    "\n",
    "# # Evaluation - see https://www.kaggle.com/uberkinder/efficient-metric\n",
    "# def group_mean_log_mae(y_true, y_pred, groups, floor=1e-9):\n",
    "#     maes = (y_true-y_pred).abs().groupby(groups).mean()\n",
    "#     return np.log(maes.map(lambda x: max(x, floor))).mean()\n",
    "\n",
    "# group_mean_log_mae(y_valid, y_pred_valid, X_valid['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 1.39461\tvalid_1's l1: 1.4081\n",
      "[200]\ttraining's l1: 1.26479\tvalid_1's l1: 1.28812\n",
      "[300]\ttraining's l1: 1.19291\tvalid_1's l1: 1.2249\n",
      "[400]\ttraining's l1: 1.14349\tvalid_1's l1: 1.18391\n",
      "[500]\ttraining's l1: 1.10456\tvalid_1's l1: 1.15287\n",
      "[600]\ttraining's l1: 1.06977\tvalid_1's l1: 1.12522\n",
      "[700]\ttraining's l1: 1.04122\tvalid_1's l1: 1.10398\n",
      "[800]\ttraining's l1: 1.01616\tvalid_1's l1: 1.08542\n",
      "[900]\ttraining's l1: 0.993311\tvalid_1's l1: 1.06919\n",
      "[1000]\ttraining's l1: 0.973141\tvalid_1's l1: 1.05543\n",
      "[1100]\ttraining's l1: 0.953642\tvalid_1's l1: 1.0418\n",
      "[1200]\ttraining's l1: 0.936898\tvalid_1's l1: 1.03095\n",
      "[1300]\ttraining's l1: 0.919211\tvalid_1's l1: 1.01896\n",
      "[1400]\ttraining's l1: 0.905512\tvalid_1's l1: 1.01098\n",
      "[1500]\ttraining's l1: 0.891099\tvalid_1's l1: 1.00195\n",
      "[1600]\ttraining's l1: 0.877934\tvalid_1's l1: 0.994187\n",
      "[1700]\ttraining's l1: 0.865195\tvalid_1's l1: 0.986451\n",
      "[1800]\ttraining's l1: 0.853789\tvalid_1's l1: 0.980228\n",
      "[1900]\ttraining's l1: 0.842598\tvalid_1's l1: 0.97412\n",
      "[2000]\ttraining's l1: 0.831568\tvalid_1's l1: 0.96796\n",
      "[2100]\ttraining's l1: 0.821123\tvalid_1's l1: 0.962229\n",
      "[2200]\ttraining's l1: 0.810894\tvalid_1's l1: 0.956818\n",
      "[2300]\ttraining's l1: 0.801652\tvalid_1's l1: 0.952105\n",
      "[2400]\ttraining's l1: 0.792603\tvalid_1's l1: 0.947479\n",
      "[2500]\ttraining's l1: 0.783832\tvalid_1's l1: 0.943217\n",
      "[2600]\ttraining's l1: 0.775219\tvalid_1's l1: 0.938897\n",
      "[2700]\ttraining's l1: 0.766399\tvalid_1's l1: 0.934226\n",
      "[2800]\ttraining's l1: 0.75834\tvalid_1's l1: 0.930272\n",
      "[2900]\ttraining's l1: 0.750313\tvalid_1's l1: 0.926391\n",
      "[3000]\ttraining's l1: 0.742713\tvalid_1's l1: 0.922743\n",
      "[3100]\ttraining's l1: 0.735335\tvalid_1's l1: 0.919356\n",
      "[3200]\ttraining's l1: 0.728395\tvalid_1's l1: 0.91641\n",
      "[3300]\ttraining's l1: 0.721335\tvalid_1's l1: 0.913193\n",
      "[3400]\ttraining's l1: 0.714386\tvalid_1's l1: 0.910144\n",
      "[3500]\ttraining's l1: 0.707828\tvalid_1's l1: 0.907287\n",
      "[3600]\ttraining's l1: 0.701169\tvalid_1's l1: 0.904291\n",
      "[3700]\ttraining's l1: 0.694786\tvalid_1's l1: 0.901413\n",
      "[3800]\ttraining's l1: 0.688832\tvalid_1's l1: 0.899087\n",
      "[3900]\ttraining's l1: 0.682456\tvalid_1's l1: 0.89607\n",
      "[4000]\ttraining's l1: 0.676465\tvalid_1's l1: 0.893542\n",
      "[4100]\ttraining's l1: 0.670845\tvalid_1's l1: 0.891311\n",
      "[4200]\ttraining's l1: 0.665172\tvalid_1's l1: 0.888964\n",
      "[4300]\ttraining's l1: 0.659717\tvalid_1's l1: 0.886842\n",
      "[4400]\ttraining's l1: 0.654474\tvalid_1's l1: 0.884952\n",
      "[4500]\ttraining's l1: 0.649231\tvalid_1's l1: 0.883004\n",
      "[4600]\ttraining's l1: 0.644082\tvalid_1's l1: 0.881024\n",
      "[4700]\ttraining's l1: 0.638969\tvalid_1's l1: 0.878985\n",
      "[4800]\ttraining's l1: 0.633856\tvalid_1's l1: 0.877037\n",
      "[4900]\ttraining's l1: 0.629025\tvalid_1's l1: 0.875225\n",
      "[5000]\ttraining's l1: 0.62414\tvalid_1's l1: 0.873303\n",
      "[5100]\ttraining's l1: 0.619515\tvalid_1's l1: 0.871742\n",
      "[5200]\ttraining's l1: 0.614838\tvalid_1's l1: 0.870066\n",
      "[5300]\ttraining's l1: 0.610199\tvalid_1's l1: 0.868463\n",
      "[5400]\ttraining's l1: 0.605449\tvalid_1's l1: 0.866618\n",
      "[5500]\ttraining's l1: 0.600993\tvalid_1's l1: 0.865022\n",
      "[5600]\ttraining's l1: 0.596677\tvalid_1's l1: 0.863572\n",
      "[5700]\ttraining's l1: 0.592416\tvalid_1's l1: 0.862095\n",
      "[5800]\ttraining's l1: 0.588112\tvalid_1's l1: 0.860621\n",
      "[5900]\ttraining's l1: 0.584017\tvalid_1's l1: 0.859281\n",
      "[6000]\ttraining's l1: 0.57981\tvalid_1's l1: 0.857789\n",
      "[6100]\ttraining's l1: 0.575656\tvalid_1's l1: 0.856347\n",
      "[6200]\ttraining's l1: 0.571661\tvalid_1's l1: 0.855035\n",
      "[6300]\ttraining's l1: 0.567742\tvalid_1's l1: 0.853809\n",
      "[6400]\ttraining's l1: 0.563881\tvalid_1's l1: 0.852552\n",
      "[6500]\ttraining's l1: 0.560063\tvalid_1's l1: 0.851348\n",
      "[6600]\ttraining's l1: 0.556396\tvalid_1's l1: 0.850197\n",
      "[6700]\ttraining's l1: 0.552629\tvalid_1's l1: 0.848935\n",
      "[6800]\ttraining's l1: 0.549012\tvalid_1's l1: 0.84781\n",
      "[6900]\ttraining's l1: 0.545361\tvalid_1's l1: 0.846626\n",
      "[7000]\ttraining's l1: 0.541859\tvalid_1's l1: 0.845588\n",
      "[7100]\ttraining's l1: 0.538295\tvalid_1's l1: 0.844471\n",
      "[7200]\ttraining's l1: 0.534822\tvalid_1's l1: 0.843472\n",
      "[7300]\ttraining's l1: 0.531365\tvalid_1's l1: 0.842417\n",
      "[7400]\ttraining's l1: 0.528002\tvalid_1's l1: 0.841524\n",
      "[7500]\ttraining's l1: 0.524683\tvalid_1's l1: 0.840653\n",
      "[7600]\ttraining's l1: 0.521312\tvalid_1's l1: 0.839692\n",
      "[7700]\ttraining's l1: 0.517927\tvalid_1's l1: 0.838619\n",
      "[7800]\ttraining's l1: 0.51469\tvalid_1's l1: 0.83772\n",
      "[7900]\ttraining's l1: 0.511489\tvalid_1's l1: 0.836801\n",
      "[8000]\ttraining's l1: 0.508246\tvalid_1's l1: 0.835816\n",
      "[8100]\ttraining's l1: 0.505073\tvalid_1's l1: 0.83495\n",
      "[8200]\ttraining's l1: 0.501926\tvalid_1's l1: 0.834073\n",
      "[8300]\ttraining's l1: 0.498837\tvalid_1's l1: 0.833229\n",
      "[8400]\ttraining's l1: 0.495765\tvalid_1's l1: 0.832419\n",
      "[8500]\ttraining's l1: 0.492643\tvalid_1's l1: 0.831484\n",
      "[8600]\ttraining's l1: 0.489663\tvalid_1's l1: 0.830733\n",
      "[8700]\ttraining's l1: 0.486658\tvalid_1's l1: 0.829851\n",
      "[8800]\ttraining's l1: 0.483775\tvalid_1's l1: 0.829103\n",
      "[8900]\ttraining's l1: 0.480909\tvalid_1's l1: 0.828375\n",
      "[9000]\ttraining's l1: 0.478063\tvalid_1's l1: 0.827592\n",
      "[9100]\ttraining's l1: 0.475284\tvalid_1's l1: 0.826901\n",
      "[9200]\ttraining's l1: 0.472436\tvalid_1's l1: 0.826119\n",
      "[9300]\ttraining's l1: 0.469691\tvalid_1's l1: 0.825368\n",
      "[9400]\ttraining's l1: 0.467015\tvalid_1's l1: 0.824683\n",
      "[9500]\ttraining's l1: 0.464345\tvalid_1's l1: 0.824015\n",
      "[9600]\ttraining's l1: 0.461737\tvalid_1's l1: 0.823364\n",
      "[9700]\ttraining's l1: 0.459127\tvalid_1's l1: 0.822796\n",
      "[9800]\ttraining's l1: 0.456451\tvalid_1's l1: 0.822061\n",
      "[9900]\ttraining's l1: 0.45379\tvalid_1's l1: 0.821365\n",
      "[10000]\ttraining's l1: 0.451341\tvalid_1's l1: 0.820801\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.451341\tvalid_1's l1: 0.820801\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.33464410445620046"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating LGBM model, single fold and iteration for now\n",
    "\n",
    "params = {'num_leaves': 128,\n",
    "          'min_child_samples': 79,\n",
    "          'objective': 'regression',\n",
    "          'max_depth': 9,\n",
    "          'learning_rate': 0.2,\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"subsample_freq\": 1,\n",
    "          \"subsample\": 0.9,\n",
    "          \"bagging_seed\": 11,\n",
    "          \"metric\": 'mae',\n",
    "          \"verbosity\": -1,\n",
    "          'reg_alpha': 0.1,\n",
    "          'reg_lambda': 0.3,\n",
    "          'colsample_bytree': 1.0\n",
    "         }\n",
    "\n",
    "verbose=100 \n",
    "early_stopping_rounds=200\n",
    "n_estimators=10000\n",
    "\n",
    "model = lgb.LGBMRegressor(**params, verbose=verbose, early_stopping_rounds=early_stopping_rounds, n_estimators=n_estimators, nthread=-1)\n",
    "\n",
    "model.fit(X_train_processed,y_train, \n",
    "              eval_set=[(X_train_processed, y_train),(X_valid_processed, y_valid)], \n",
    "              eval_metric='mae',\n",
    "              verbose=verbose)\n",
    "y_pred_valid = model.predict(X_valid_processed)\n",
    "y_pred = model.predict(X_test_processed)\n",
    "\n",
    "# Evaluation - see https://www.kaggle.com/uberkinder/efficient-metric\n",
    "def group_mean_log_mae(y_true, y_pred, groups, floor=1e-9):\n",
    "    maes = (y_true-y_pred).abs().groupby(groups).mean()\n",
    "    return np.log(maes.map(lambda x: max(x, floor))).mean()\n",
    "\n",
    "group_mean_log_mae(y_valid, y_pred_valid, X_valid['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-efc706bca97f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m pd.DataFrame(\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m ).to_csv('{}'.format(file_name), index=False, header=header)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "#Submitting\n",
    "file_name = \"solution.csv\"\n",
    "message = \"XGBoost unoptimised with distance features\"\n",
    "header = ['id','scalar_coupling_constant']\n",
    "\n",
    "\n",
    "\n",
    "pd.DataFrame(\n",
    "    data=list(zip([x for x in test_df['id'].tolist()], [int(x) for x in predictions.tolist()]))\n",
    ").to_csv('{}'.format(file_name), index=False, header=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$file_name\" \"$message\"\n",
    "kaggle competitions submit -c home-data-for-ml-course -f $1 -m \"$2\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
