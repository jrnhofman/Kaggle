{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo\n",
    "# Create features out of fold\n",
    "# Train per type\n",
    "# Add common atom interactions (radii and interaction formulas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb\n",
    "\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbm_params = {\n",
    "\n",
    "    'num_leaves': 128,\n",
    "    'min_child_samples': 79,\n",
    "    'objective': 'regression',\n",
    "    'max_depth': 9,\n",
    "    'learning_rate': 0.2,\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"subsample_freq\": 1,\n",
    "    \"subsample\": 0.9,\n",
    "    \"bagging_seed\": 11,\n",
    "    \"metric\": 'mae',\n",
    "    \"verbosity\": -1,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.3,\n",
    "    'colsample_bytree': 1.0,\n",
    "    'verbose': 100, \n",
    "\n",
    "    # Play with these\n",
    "    'early_stopping_rounds' : 200,\n",
    "    'n_estimators': 10000,\n",
    "\n",
    "}\n",
    "\n",
    "# Evaluation - see https://www.kaggle.com/uberkinder/efficient-metric\n",
    "def group_mean_log_mae(y_true, y_pred, groups, floor=1e-9):\n",
    "    maes = (y_true-y_pred).abs().groupby(groups).mean()\n",
    "    return np.log(maes.map(lambda x: max(x, floor))).mean()\n",
    "\n",
    "\n",
    "\n",
    "def do_cross_validation(\n",
    "    train_df\n",
    "    , y\n",
    "    , test_df\n",
    "    , n_folds = 5\n",
    "    , n_reshuffles = 1\n",
    "    , shuffle = True\n",
    "    , random_state=42\n",
    "    , estimator = 'lightgbm'\n",
    "    , metric = 'group_mean_log_mae'\n",
    "    , **kwargs\n",
    "):\n",
    "\n",
    "\n",
    "    \n",
    "    predictions = np.zeros([test_df.shape[0],n_folds*n_reshuffles])\n",
    "    train_score = np.zeros([n_folds*n_reshuffles])\n",
    "    val_score = np.zeros([n_folds*n_reshuffles]) \n",
    "    \n",
    "    for s in range(n_reshuffles):\n",
    "        print('Reshuffle: ', s)\n",
    "        kf = KFold(n_splits=n_folds, shuffle=shuffle, random_state=random_state)\n",
    "        \n",
    "        for fold, (train_index, val_index) in enumerate(kf.split(np.array(train_df))):\n",
    "            print('Training fold: ', fold)\n",
    "\n",
    "            X_train, X_val = np.array(train_df)[train_index], np.array(train_df)[val_index]\n",
    "            y_train, y_val = y[train_index], y[val_index]\n",
    "            \n",
    "            if metric == 'group_mean_log_mae':\n",
    "                X_train_types, X_val_types = kwargs['train_types'][train_index], kwargs['train_types'][val_index]\n",
    "\n",
    "            if estimator == 'lightgbm':\n",
    "                \n",
    "                lightgbm_params = kwargs['lightgbm_params']\n",
    "                model = lgb.LGBMRegressor(\n",
    "                            **lightgbm_params\n",
    "                            , nthread=-1)\n",
    "\n",
    "                model.fit(X_train,y_train, \n",
    "                              eval_set=[(X_train, y_train),(X_val, y_val)], \n",
    "                              eval_metric=lightgbm_params['metric'],\n",
    "                              verbose=lightgbm_params['verbose'])\n",
    "\n",
    "            y_train_pred = model.predict(X_train)\n",
    "            y_val_pred = model.predict(X_val)\n",
    "            y_pred = model.predict(test_df)\n",
    "\n",
    "            if metric == 'group_mean_log_mae':\n",
    "                train_score[s*n_folds + fold] = group_mean_log_mae(y_train_pred, y_train, X_train_types)\n",
    "                val_score[s*n_folds + fold] = group_mean_log_mae(y_val_pred, y_val, X_val_types)\n",
    "            \n",
    "            predictions[:,s*n_folds + fold] = y_pred\n",
    "            \n",
    "            print(\"Training score: \", train_score[-1])\n",
    "            print(\"Validiation score: \", val_score[-1])\n",
    "            \n",
    "    \n",
    "    return train_score, val_score, predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training sample:  (4658147, 6)\n",
      "Shape of testing sample:  (2505542, 5)\n",
      "Shape of structures sample:  (2358657, 6)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('../champs-scalar-coupling/train.csv')\n",
    "test_df = pd.read_csv('../champs-scalar-coupling/test.csv')\n",
    "structures_df = pd.read_csv('../champs-scalar-coupling/structures.csv')\n",
    "\n",
    "print(\"Shape of training sample: \",train_df.shape)\n",
    "print(\"Shape of testing sample: \",test_df.shape)\n",
    "print(\"Shape of structures sample: \",structures_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>molecule_name</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>type</th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "      <th>atom_0</th>\n",
       "      <th>x_0</th>\n",
       "      <th>y_0</th>\n",
       "      <th>z_0</th>\n",
       "      <th>atom_1</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>z_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.8076</td>\n",
       "      <td>H</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.2570</td>\n",
       "      <td>H</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>H</td>\n",
       "      <td>1.011731</td>\n",
       "      <td>1.463751</td>\n",
       "      <td>0.000277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.2548</td>\n",
       "      <td>H</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>H</td>\n",
       "      <td>-0.540815</td>\n",
       "      <td>1.447527</td>\n",
       "      <td>-0.876644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.2543</td>\n",
       "      <td>H</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>H</td>\n",
       "      <td>-0.523814</td>\n",
       "      <td>1.437933</td>\n",
       "      <td>0.906397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>dsgdb9nsd_000001</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.8074</td>\n",
       "      <td>H</td>\n",
       "      <td>1.011731</td>\n",
       "      <td>1.463751</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     molecule_name  atom_index_0  atom_index_1  type  \\\n",
       "0   0  dsgdb9nsd_000001             1             0  1JHC   \n",
       "1   1  dsgdb9nsd_000001             1             2  2JHH   \n",
       "2   2  dsgdb9nsd_000001             1             3  2JHH   \n",
       "3   3  dsgdb9nsd_000001             1             4  2JHH   \n",
       "4   4  dsgdb9nsd_000001             2             0  1JHC   \n",
       "\n",
       "   scalar_coupling_constant atom_0       x_0       y_0       z_0 atom_1  \\\n",
       "0                   84.8076      H  0.002150 -0.006031  0.001976      C   \n",
       "1                  -11.2570      H  0.002150 -0.006031  0.001976      H   \n",
       "2                  -11.2548      H  0.002150 -0.006031  0.001976      H   \n",
       "3                  -11.2543      H  0.002150 -0.006031  0.001976      H   \n",
       "4                   84.8074      H  1.011731  1.463751  0.000277      C   \n",
       "\n",
       "        x_1       y_1       z_1  \n",
       "0 -0.012698  1.085804  0.008001  \n",
       "1  1.011731  1.463751  0.000277  \n",
       "2 -0.540815  1.447527 -0.876644  \n",
       "3 -0.523814  1.437933  0.906397  \n",
       "4 -0.012698  1.085804  0.008001  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Joining structure data onto train/test set\n",
    "tmp_with_atom0_info = (train_df\n",
    "                           .merge( structures_df, left_on = ['molecule_name','atom_index_0'], right_on = ['molecule_name','atom_index'], how = 'left' )\n",
    "                           .drop('atom_index', axis=1)\n",
    "                       )\n",
    "tmp_with_atom0_info = tmp_with_atom0_info.rename(columns={ 'atom' : 'atom_0', 'x' : 'x_0', 'y' : 'y_0', 'z' : 'z_0'})\n",
    "\n",
    "tmp_with_atom1_info = (tmp_with_atom0_info\n",
    "                           .merge( structures_df, left_on = ['molecule_name','atom_index_1'], right_on = ['molecule_name','atom_index'], how = 'left' )\n",
    "                           .drop('atom_index', axis=1)\n",
    "                       )\n",
    "tmp_with_atom1_info = tmp_with_atom1_info.rename(columns={ 'atom' : 'atom_1', 'x' : 'x_1', 'y' : 'y_1', 'z' : 'z_1'})\n",
    "\n",
    "train_df = tmp_with_atom1_info\n",
    "\n",
    "tmp_with_atom0_info = (test_df\n",
    "                           .merge( structures_df, left_on = ['molecule_name','atom_index_0'], right_on = ['molecule_name','atom_index'], how = 'left' )\n",
    "                           .drop('atom_index', axis=1)\n",
    "                       )\n",
    "tmp_with_atom0_info = tmp_with_atom0_info.rename(columns={ 'atom' : 'atom_0', 'x' : 'x_0', 'y' : 'y_0', 'z' : 'z_0'})\n",
    "\n",
    "tmp_with_atom1_info = (tmp_with_atom0_info\n",
    "                           .merge( structures_df, left_on = ['molecule_name','atom_index_1'], right_on = ['molecule_name','atom_index'], how = 'left' )\n",
    "                           .drop('atom_index', axis=1)\n",
    "                       )\n",
    "tmp_with_atom1_info = tmp_with_atom1_info.rename(columns={ 'atom' : 'atom_1', 'x' : 'x_1', 'y' : 'y_1', 'z' : 'z_1'})\n",
    "\n",
    "test_df = tmp_with_atom1_info\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del structures_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing distances\n",
    "\n",
    "train_p_0 = train_df[['x_0', 'y_0', 'z_0']].values\n",
    "train_p_1 = train_df[['x_1', 'y_1', 'z_1']].values\n",
    "test_p_0 = test_df[['x_0', 'y_0', 'z_0']].values\n",
    "test_p_1 = test_df[['x_1', 'y_1', 'z_1']].values\n",
    "\n",
    "train_df['dist'] = np.linalg.norm(train_p_0 - train_p_1, axis=1)\n",
    "test_df['dist'] = np.linalg.norm(test_p_0 - test_p_1, axis=1)\n",
    "train_df['dist_x'] = (train_df['x_0'] - train_df['x_1']) ** 2\n",
    "test_df['dist_x'] = (test_df['x_0'] - test_df['x_1']) ** 2\n",
    "train_df['dist_y'] = (train_df['y_0'] - train_df['y_1']) ** 2\n",
    "test_df['dist_y'] = (test_df['y_0'] - test_df['y_1']) ** 2\n",
    "train_df['dist_z'] = (train_df['z_0'] - train_df['z_1']) ** 2\n",
    "test_df['dist_z'] = (test_df['z_0'] - test_df['z_1']) ** 2\n",
    "\n",
    "train_df['type_0'] = train_df['type'].apply(lambda x: x[0])\n",
    "test_df['type_0'] = test_df['type'].apply(lambda x: x[0])\n",
    "\n",
    "train_df['type_1'] = train_df['type'].apply(lambda x: x[1:])\n",
    "test_df['type_1'] = test_df['type'].apply(lambda x: x[1:])\n",
    "\n",
    "# Some more distances related to average molecule and type distances\n",
    "# Freely adapted after https://www.kaggle.com/artgor/brute-force-feature-engineering\n",
    "def create_features(df):\n",
    "    df['molecule_couples'] = df.groupby('molecule_name')['id'].transform('count')\n",
    "    df['molecule_dist_mean'] = df.groupby('molecule_name')['dist'].transform('mean')\n",
    "    df['molecule_dist_min'] = df.groupby('molecule_name')['dist'].transform('min')\n",
    "    df['molecule_dist_max'] = df.groupby('molecule_name')['dist'].transform('max')\n",
    "    df['atom_0_couples_count'] = df.groupby(['molecule_name', 'atom_index_0'])['id'].transform('count')\n",
    "    df['atom_1_couples_count'] = df.groupby(['molecule_name', 'atom_index_1'])['id'].transform('count')\n",
    "    \n",
    "    df[f'molecule_atom_index_0_x_1_std'] = df.groupby(['molecule_name', 'atom_index_0'])['x_1'].transform('std')\n",
    "    df[f'molecule_atom_index_0_y_1_mean'] = df.groupby(['molecule_name', 'atom_index_0'])['y_1'].transform('mean')\n",
    "    df[f'molecule_atom_index_0_y_1_mean_diff'] = df[f'molecule_atom_index_0_y_1_mean'] - df['y_1']\n",
    "    df[f'molecule_atom_index_0_y_1_mean_div'] = df[f'molecule_atom_index_0_y_1_mean'] / df['y_1']\n",
    "    df[f'molecule_atom_index_0_y_1_max'] = df.groupby(['molecule_name', 'atom_index_0'])['y_1'].transform('max')\n",
    "    df[f'molecule_atom_index_0_y_1_max_diff'] = df[f'molecule_atom_index_0_y_1_max'] - df['y_1']\n",
    "    df[f'molecule_atom_index_0_y_1_std'] = df.groupby(['molecule_name', 'atom_index_0'])['y_1'].transform('std')\n",
    "    df[f'molecule_atom_index_0_z_1_std'] = df.groupby(['molecule_name', 'atom_index_0'])['z_1'].transform('std')\n",
    "    df[f'molecule_atom_index_0_dist_mean'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('mean')\n",
    "    df[f'molecule_atom_index_0_dist_mean_diff'] = df[f'molecule_atom_index_0_dist_mean'] - df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_mean_div'] = df[f'molecule_atom_index_0_dist_mean'] / df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_max'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('max')\n",
    "    df[f'molecule_atom_index_0_dist_max_diff'] = df[f'molecule_atom_index_0_dist_max'] - df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_max_div'] = df[f'molecule_atom_index_0_dist_max'] / df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_min'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('min')\n",
    "    df[f'molecule_atom_index_0_dist_min_diff'] = df[f'molecule_atom_index_0_dist_min'] - df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_min_div'] = df[f'molecule_atom_index_0_dist_min'] / df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_std'] = df.groupby(['molecule_name', 'atom_index_0'])['dist'].transform('std')\n",
    "    df[f'molecule_atom_index_0_dist_std_diff'] = df[f'molecule_atom_index_0_dist_std'] - df['dist']\n",
    "    df[f'molecule_atom_index_0_dist_std_div'] = df[f'molecule_atom_index_0_dist_std'] / df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_mean'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('mean')\n",
    "    df[f'molecule_atom_index_1_dist_mean_diff'] = df[f'molecule_atom_index_1_dist_mean'] - df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_mean_div'] = df[f'molecule_atom_index_1_dist_mean'] / df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_max'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('max')\n",
    "    df[f'molecule_atom_index_1_dist_max_diff'] = df[f'molecule_atom_index_1_dist_max'] - df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_max_div'] = df[f'molecule_atom_index_1_dist_max'] / df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_min'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('min')\n",
    "    df[f'molecule_atom_index_1_dist_min_diff'] = df[f'molecule_atom_index_1_dist_min'] - df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_min_div'] = df[f'molecule_atom_index_1_dist_min'] / df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_std'] = df.groupby(['molecule_name', 'atom_index_1'])['dist'].transform('std')\n",
    "    df[f'molecule_atom_index_1_dist_std_diff'] = df[f'molecule_atom_index_1_dist_std'] - df['dist']\n",
    "    df[f'molecule_atom_index_1_dist_std_div'] = df[f'molecule_atom_index_1_dist_std'] / df['dist']\n",
    "    df[f'molecule_atom_1_dist_mean'] = df.groupby(['molecule_name', 'atom_1'])['dist'].transform('mean')\n",
    "    df[f'molecule_atom_1_dist_min'] = df.groupby(['molecule_name', 'atom_1'])['dist'].transform('min')\n",
    "    df[f'molecule_atom_1_dist_min_diff'] = df[f'molecule_atom_1_dist_min'] - df['dist']\n",
    "    df[f'molecule_atom_1_dist_min_div'] = df[f'molecule_atom_1_dist_min'] / df['dist']\n",
    "    df[f'molecule_atom_1_dist_std'] = df.groupby(['molecule_name', 'atom_1'])['dist'].transform('std')\n",
    "    df[f'molecule_atom_1_dist_std_diff'] = df[f'molecule_atom_1_dist_std'] - df['dist']\n",
    "    df[f'molecule_type_0_dist_std'] = df.groupby(['molecule_name', 'type_0'])['dist'].transform('std')\n",
    "    df[f'molecule_type_0_dist_std_diff'] = df[f'molecule_type_0_dist_std'] - df['dist']\n",
    "    df[f'molecule_type_1_dist_std'] = df.groupby(['molecule_name', 'type_1'])['dist'].transform('std')\n",
    "    df[f'molecule_type_1_dist_std_diff'] = df[f'molecule_type_1_dist_std'] - df['dist']\n",
    "    df[f'molecule_type_dist_mean'] = df.groupby(['molecule_name', 'type'])['dist'].transform('mean')\n",
    "    df[f'molecule_type_dist_mean_diff'] = df[f'molecule_type_dist_mean'] - df['dist']\n",
    "    df[f'molecule_type_dist_mean_div'] = df[f'molecule_type_dist_mean'] / df['dist']\n",
    "    df[f'molecule_type_dist_max'] = df.groupby(['molecule_name', 'type'])['dist'].transform('max')\n",
    "    df[f'molecule_type_dist_min'] = df.groupby(['molecule_name', 'type'])['dist'].transform('min')\n",
    "    df[f'molecule_type_dist_std'] = df.groupby(['molecule_name', 'type'])['dist'].transform('std')\n",
    "    df[f'molecule_type_dist_std_diff'] = df[f'molecule_type_dist_std'] - df['dist']\n",
    "\n",
    "    return df\n",
    "\n",
    "y = train_df['scalar_coupling_constant']\n",
    "\n",
    "train_types = train_df['type']\n",
    "test_types = test_df['type']\n",
    "\n",
    "train_df = create_features(train_df).drop(['id', 'molecule_name', 'scalar_coupling_constant'], axis=1)\n",
    "test_df = create_features(test_df).drop(['id', 'molecule_name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), ['atom_0', 'atom_1', 'type', 'type_0', 'type_1'])\n",
    "    ] )\n",
    "\n",
    "preprocessor.fit(train_df)\n",
    "\n",
    "train_df_final = train_df.copy()\n",
    "test_df_final = test_df.copy()\n",
    "\n",
    "train_df_final[preprocessor.get_feature_names()] = pd.DataFrame(preprocessor.transform(train_df).toarray(),columns=preprocessor.get_feature_names())\n",
    "test_df_final[preprocessor.get_feature_names()] = pd.DataFrame(preprocessor.transform(test_df).toarray(),columns=preprocessor.get_feature_names())\n",
    "\n",
    "train_df_final.drop(['atom_0', 'atom_1', 'type', 'type_0', 'type_1'],axis=1,inplace=True)\n",
    "test_df_final.drop(['atom_0', 'atom_1', 'type', 'type_0', 'type_1'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>x_0</th>\n",
       "      <th>y_0</th>\n",
       "      <th>z_0</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>z_1</th>\n",
       "      <th>dist</th>\n",
       "      <th>dist_x</th>\n",
       "      <th>...</th>\n",
       "      <th>cat__x2_2JHN</th>\n",
       "      <th>cat__x2_3JHC</th>\n",
       "      <th>cat__x2_3JHH</th>\n",
       "      <th>cat__x2_3JHN</th>\n",
       "      <th>cat__x3_1</th>\n",
       "      <th>cat__x3_2</th>\n",
       "      <th>cat__x3_3</th>\n",
       "      <th>cat__x4_JHC</th>\n",
       "      <th>cat__x4_JHH</th>\n",
       "      <th>cat__x4_JHN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "      <td>1.091953</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>1.011731</td>\n",
       "      <td>1.463751</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>1.783120</td>\n",
       "      <td>1.019253</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>-0.540815</td>\n",
       "      <td>1.447527</td>\n",
       "      <td>-0.876644</td>\n",
       "      <td>1.783147</td>\n",
       "      <td>0.294812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>-0.523814</td>\n",
       "      <td>1.437933</td>\n",
       "      <td>0.906397</td>\n",
       "      <td>1.783157</td>\n",
       "      <td>0.276638</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.011731</td>\n",
       "      <td>1.463751</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "      <td>1.091952</td>\n",
       "      <td>1.049455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   atom_index_0  atom_index_1       x_0       y_0       z_0       x_1  \\\n",
       "0             1             0  0.002150 -0.006031  0.001976 -0.012698   \n",
       "1             1             2  0.002150 -0.006031  0.001976  1.011731   \n",
       "2             1             3  0.002150 -0.006031  0.001976 -0.540815   \n",
       "3             1             4  0.002150 -0.006031  0.001976 -0.523814   \n",
       "4             2             0  1.011731  1.463751  0.000277 -0.012698   \n",
       "\n",
       "        y_1       z_1      dist    dist_x  ...  cat__x2_2JHN  cat__x2_3JHC  \\\n",
       "0  1.085804  0.008001  1.091953  0.000220  ...           0.0           0.0   \n",
       "1  1.463751  0.000277  1.783120  1.019253  ...           0.0           0.0   \n",
       "2  1.447527 -0.876644  1.783147  0.294812  ...           0.0           0.0   \n",
       "3  1.437933  0.906397  1.783157  0.276638  ...           0.0           0.0   \n",
       "4  1.085804  0.008001  1.091952  1.049455  ...           0.0           0.0   \n",
       "\n",
       "   cat__x2_3JHH  cat__x2_3JHN  cat__x3_1  cat__x3_2  cat__x3_3  cat__x4_JHC  \\\n",
       "0           0.0           0.0        1.0        0.0        0.0          1.0   \n",
       "1           0.0           0.0        0.0        1.0        0.0          0.0   \n",
       "2           0.0           0.0        0.0        1.0        0.0          0.0   \n",
       "3           0.0           0.0        0.0        1.0        0.0          0.0   \n",
       "4           0.0           0.0        1.0        0.0        0.0          1.0   \n",
       "\n",
       "   cat__x4_JHH  cat__x4_JHN  \n",
       "0          0.0          0.0  \n",
       "1          1.0          0.0  \n",
       "2          1.0          0.0  \n",
       "3          1.0          0.0  \n",
       "4          0.0          0.0  \n",
       "\n",
       "[5 rows x 85 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshuffle:  0\n",
      "Training fold:  0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 1.39342\tvalid_1's l1: 1.40612\n",
      "[200]\ttraining's l1: 1.26879\tvalid_1's l1: 1.29189\n",
      "[300]\ttraining's l1: 1.19478\tvalid_1's l1: 1.22653\n",
      "[400]\ttraining's l1: 1.14358\tvalid_1's l1: 1.18299\n",
      "[500]\ttraining's l1: 1.10296\tvalid_1's l1: 1.15036\n",
      "[600]\ttraining's l1: 1.06914\tvalid_1's l1: 1.12382\n",
      "[700]\ttraining's l1: 1.04091\tvalid_1's l1: 1.10259\n",
      "[800]\ttraining's l1: 1.01574\tvalid_1's l1: 1.08442\n",
      "[900]\ttraining's l1: 0.993118\tvalid_1's l1: 1.06828\n",
      "[1000]\ttraining's l1: 0.972813\tvalid_1's l1: 1.05442\n",
      "[1100]\ttraining's l1: 0.953677\tvalid_1's l1: 1.04147\n",
      "[1200]\ttraining's l1: 0.936119\tvalid_1's l1: 1.02963\n",
      "[1300]\ttraining's l1: 0.92049\tvalid_1's l1: 1.01985\n",
      "[1400]\ttraining's l1: 0.906171\tvalid_1's l1: 1.01113\n",
      "[1500]\ttraining's l1: 0.891385\tvalid_1's l1: 1.00158\n",
      "[1600]\ttraining's l1: 0.878292\tvalid_1's l1: 0.993718\n",
      "[1700]\ttraining's l1: 0.865437\tvalid_1's l1: 0.985787\n",
      "[1800]\ttraining's l1: 0.853349\tvalid_1's l1: 0.978684\n",
      "[1900]\ttraining's l1: 0.842117\tvalid_1's l1: 0.972565\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-cb4ea574fe97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;34m,\u001b[0m\u001b[0mtrain_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;34m,\u001b[0m\u001b[0mtest_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         ,lightgbm_params=lightgbm_params)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-d3d3667cde8e>\u001b[0m in \u001b[0;36mdo_cross_validation\u001b[0;34m(train_df, y, test_df, n_folds, n_reshuffles, shuffle, random_state, estimator, metric, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m                               \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                               \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlightgbm_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metric'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                               verbose=lightgbm_params['verbose'])\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0my_train_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jhofman/.local/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    683\u001b[0m                                        \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m                                        \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                                        callbacks=callbacks)\n\u001b[0m\u001b[1;32m    686\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jhofman/.local/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    542\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jhofman/.local/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    216\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jhofman/.local/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1800\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1802\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1803\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1804\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_score, val_score, predictions = do_cross_validation(\n",
    "        train_df_final\n",
    "        ,y\n",
    "        ,test_df_final\n",
    "    \n",
    "        ,train_types=train_types\n",
    "        ,test_types=test_types\n",
    "        ,lightgbm_params=lightgbm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
